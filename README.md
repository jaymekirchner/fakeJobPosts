# Predicting Job Postings as Real or Fake
This project looks to address the problem of fake job postings and tries to predict whether a given job posting fraudulent based on its text. The data was highly imbalanced with only 5% fraudulent postings and required extensive preprocessing to replace missing values. The baseline model was a RNN (Recurrent Neural Network) with an Embedding layer and a Bidirectional LSTM layer, and its results were compared with a BERT (Bidirectional Encoder Representations from Transformers) model. Due to resource constraints, the Small-BERT architecture was applied.  Initially, the baseline model was trained on all data (numeric and textual) but the AUC of 50% was no better than a random classifier so the project instead focused solely on the textual data. The twelve text columns in the dataset were split into five groups to be passed as inputs to each model. After five epochs, the baseline RNN resulted in a validation AUC of 0.7974 with 139 False Negatives; and the test data had a final AUC of 0.7864 with 173 False Negatives. The Small-BERT model ran for a single epoch on the same five text groupings and yielded significantly higher results. The validation AUC was 0.9625 with 109 False Negatives and 1 False Positive; and the testing AUC was 0.9637 with 119 False Negatives and 4 False Positives. The ability of both models to distinguish between fraudulent and real postings on heavily imbalanced data is promising, but it highlights the need for job posters to be diligent in creating complete job postings, and for job seekers to read all postings with a critical eye. 

## Included in file
* Jupyter Notebook built in Google Colab
* Powerpoint slide show of results
